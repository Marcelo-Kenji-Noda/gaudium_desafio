# ğŸš€ Desafio TÃ©cnico - Gaudium

## ğŸ“ Estrutura dos dados

Arquivo de entrada: `Dados brutos.csv`
| Coluna       | Tipo |
|--------------|------|
| nome_cliente | str  |
| cidade       | str  |
| estado       | str  |
| nome_produto | str  |
| categoria    | str  |
| fabricante   | str  |
| data         | date |
| qtd_vendida  | int  |
| valor_total  | int  |

A configuraÃ§Ã£o ``inferSchema=True`` do mÃ©todo de leitura de arquivo PySpark foi capaz de capturar o schema de forma correta

## ğŸ“‹ IdentificaÃ§Ã£o de entidades e fatos

A partir de uma anÃ¡lise inicial, foi possÃ­vel identificar as dimensÃµes/contexto de clientes, produtos e data e os fatos, relacionados as medidas de quantidade vendida e valor total

As tabelas de dimensÃµes criadas foram:

### Cliente

A tabela de cliente utiliza o nome, cidade e estado para identificar um cliente Ãºnico e o id gerado para essa tabela Ã© um hash obtido atravÃ©s da combinaÃ§Ã£o desses trÃªs valores

| Coluna       | Tipo |
|--------------|------|
| id_cliente   | int  |
| nome_cliente | str  |
| cidade       | str  |
| estado       | str  |

### Produtos

A tabela de produtos utiliza o nome e fabricante para identificar um produto Ãºnico e o id gerado para essa tabela Ã© um hash obtido atravÃ©s da combinaÃ§Ã£o desses dois valores

| Coluna       | Tipo |
|--------------|------|
| id_produtos   | int  |
| nome_produto | str  |
| categoria       | str  |
| fabricante       | str  |

### Datas

A tabela de dias Ã© gerado referenciando a data da primeira compra registrada e a data da Ãºltima compra registrada como bases para gerar o intervalo completo de dias nesse intervalo. AlÃ©m disso, a tabela de datas contÃ©m informaÃ§Ãµes como o dia, mÃªs, ano e dia da semana para possÃ­vel utilizaÃ§Ã£o por parte da equipe de anÃ¡lise ou da equipe de ciÃªncia de dados

| Coluna       | Tipo |
|--------------|------|
| data   | date  |
| dia | int  |
| mes       | int  |
|    ano    | int  |
|    dia_da_semana    | int  |

### Vendas fato

A tabela de vendas fato Ã© a tabela central, no qual o contexto dessas dimensÃµes sÃ£o aplicadas. 
A granularidade dela Ã© por cliente, dia e produto e contÃ©m as informaÃ§Ãµes de quantidade vendida e total. Ela foi gerada usando o arquivo bruto como base.

| Coluna       | Tipo |
|--------------|------|
| data   | date  |
| id_cliente | int  |
| id_produto       | int  |
|    qtde_vendida    | int  |
|    valor_total    | int  |

## ğŸ— Diagrama do modelo e das etapas de transformaÃ§Ã£o dos dados

O diagrama Ã© uma representaÃ§Ã£o simplificada de como os dados estÃ£o sendo transformados. Ela nÃ£o segue uma estrutura usual de diagramaÃ§Ã£o de ETL, visto que o intuito Ã© simplismente ilustrar de forma clara o processo especÃ­fico para o desenvolvimento desse projeto particular.

![image](imgs/diagram.jpg)

## â–¶ï¸ Como executar o cÃ³digo

CÃ³digo principal

PrÃ©-requisito para executar o cÃ³digo
- Suba os arquivos main.py e config.toml para um ambiente com suporte ao pyspark
- Suba o arquivo .csv. Por padrÃ£o o script espera que o arquivo esteja em um diretÃ³rio data/raw/ no mesmo local que o main, porÃ©m, isso pode ser alterado no arquivo de configuraÃ§Ã£o (config.toml)
- Execute o cÃ³digo main.py
- Os arquivos serÃ£o gerados dentro do diretÃ³rios determinados pelo arquivo de configuraÃ§Ã£o (por padrÃ£o, data/processed/)

---
CÃ³digo notebook

VersÃ£o utilizada para testagem individual de cada base de dados e pode ser utilizado para investigar cada processo individualemente

- Suba o notebook e o arquivo .csv em um ambiente com suporte ao pyspark

## ğŸ›  Tecnologias utilizadas

- PySpark
- Spark SQL
- Microsoft Fabric (simulado via notebooks)
- Git e GitHub
- Figma (Para geraÃ§Ã£o dos diagramas)

## ğŸ“‚ Arquivos no repositÃ³rio

A estrutura de arquivos do repositÃ³rio

- `notebooks/modelagem.ipynb`
    - Notebook que pode ser utilizado para gerar os dados, porÃ©m, mais recomendado para testar funÃ§Ãµes e transformaÃ§Ãµes especÃ­ficas para algum dos arquivos
- `main.py`
    - Script principal
- `config.toml`
    - Arquivo de configuraÃ§Ã£o para execuÃ§Ã£o do script `main.py`
    - A partir desse arquivo, pode ser alterado o caminho dos arquivos de entrada e saÃ­da de cada tabela, quais arquivos devem ser consolidados e tambÃ©m quais colunas serÃ£o utilizadas como identificadores Ãºnicos
- `requirements_dev.txt`
    - Arquivo com os pacotes utilizados e suas versÃµes

#### Arquivos gerados
Os arquivos de saÃ­da foram geradas de forma a simular um processo de ETL.

```
data
â”œâ”€â”€â”€processed
â”‚   â””â”€â”€ cliente
â”‚       â”œâ”€â”€ clientes_YYYYmmmdd.csv
â”‚       â””â”€â”€ clientes.csv
â”‚   â””â”€â”€ datas
â”‚       â”œâ”€â”€ datas_YYYYmmmdd.csv
â”‚       â””â”€â”€ datas.csv
â”‚   â””â”€â”€ produtos
â”‚       â”œâ”€â”€ produtos_YYYYmmmdd.csv
â”‚       â””â”€â”€ produtos.csv
â”‚   â””â”€â”€ vendas_fato.csv
â”‚       â”œâ”€â”€ vendas_fato_YYYYmmmdd.csv
â”‚       â””â”€â”€ vendas_fato.csv
â””â”€â”€â”€raw
    â””â”€â”€â”€ Dados brutos.csv
```

ObservaÃ§Ã£o:
- SÃ£o gerados dois arquivos para cada grupo de dados, uma versÃ£o que sempre serÃ¡ a mais recente e outra contendo a informaÃ§Ã£o da data de geraÃ§Ã£o, que pode ser utilizado para versionamento.
 

## âœ… ObservaÃ§Ãµes
